{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RTT9CXZH4H9q",
        "outputId": "a0d56391-86fd-44ea-b95e-c0c6dd6812de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tadasets\n",
            "  Downloading tadasets-0.2.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from tadasets) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tadasets) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tadasets) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->tadasets) (1.17.0)\n",
            "Downloading tadasets-0.2.2-py3-none-any.whl (9.7 kB)\n",
            "Installing collected packages: tadasets\n",
            "Successfully installed tadasets-0.2.2\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (2.0.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-3.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (3.1.4)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (3.1.2)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (11.3.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.12/dist-packages (from open3d) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from open3d) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.12/dist-packages (from open3d) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from open3d) (4.67.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (4.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (2.32.4)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>=3.0.0->open3d) (3.0.3)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.16)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->open3d) (2.9.0.post0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7.0->open3d) (5.9.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->open3d) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.30.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.5.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->dash>=2.6.0->open3d) (2025.11.12)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.14)\n",
            "Downloading open3d-0.19.0-cp312-cp312-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-3.3.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.3 configargparse-1.7.1 dash-3.3.0 ipywidgets-8.1.8 jedi-0.19.2 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.2 widgetsnbextension-4.0.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipywidgets"
                ]
              },
              "id": "ae9d0281221d4fa1900ad8bb667cf696"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2956313940.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen3d\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m \u001b[0;31m#for USA dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"\"\"A node class for A* Pathfinding\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import math as math\n",
        "import random\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_swiss_roll\n",
        "from scipy.linalg import svd\n",
        "import statistics\n",
        "from matplotlib import colors, cm\n",
        "#!pip install sci-kit spatial\n",
        "#from sk.spatial.objects import Line\n",
        "class SOM():\n",
        "    def __init__(self, dataset, topoMap, initMethod, N, size, seed=None): # initializes our SOM\n",
        "        self.dataset = dataset\n",
        "        self.topoMap = topoMap\n",
        "        self.initMethod = initMethod\n",
        "        self.N = N\n",
        "        self.size = int(size)\n",
        "        self.seed = seed\n",
        "        self.map_nodes = N**2\n",
        "\n",
        "        if topoMap == 'line':\n",
        "          self.map_nodes = N\n",
        "        random_x = [0] * self.size\n",
        "        random_y = [0] * self.size\n",
        "        random_z = [0] * self.size\n",
        "        random_a = [0] * self.size\n",
        "\n",
        "        #generate datasets\n",
        "        if(self.dataset == \"swiss_roll\"):\n",
        "\n",
        "          #saves swissroll dataset as a csv file (write to csv)\n",
        "\n",
        "          x, t = make_swiss_roll(n_samples=self.size)\n",
        "\n",
        "          random_x=[(x[i,0]) for i in range(self.size)]\n",
        "          random_y=[(x[i,1]) for i in range(self.size)]\n",
        "          random_z=[(x[i,2]) for i in range(self.size)]\n",
        "\n",
        "          meanx = statistics.mean(random_x)\n",
        "          meany = statistics.mean(random_y)\n",
        "          meanz = statistics.mean(random_z)\n",
        "\n",
        "          for i in range(self.size):\n",
        "            random_x[i] -= meanx\n",
        "            random_y[i] -= meany\n",
        "            random_z[i] -= meanz\n",
        "\n",
        "          random_d = [random_x, random_y, random_z]\n",
        "          np.savetxt('swiss_roll.csv', (random_x, random_y, random_z), delimiter=',',fmt='%f')\n",
        "\n",
        "          #loads swissroll dataset from a csv file (read csv)\n",
        "          data = pd.read_csv(\"swiss_roll.csv\", header=None)\n",
        "\n",
        "          random_d = []\n",
        "          for i in range(len(data)):\n",
        "            temp = []\n",
        "            for j in range(len(data.columns)):\n",
        "              temp.append(data.iat[i, j])\n",
        "            random_d.append(temp)\n",
        "          for i in range(len(random_d)):\n",
        "            print(random_d[i])\n",
        "\n",
        "        elif(self.dataset == \"s_curve\"):\n",
        "          x, t = make_s_curve(n_samples=self.size)\n",
        "\n",
        "          random_x=[(x[i,0]) for i in range(self.size)]\n",
        "          random_y=[(x[i,1]) for i in range(self.size)]\n",
        "          random_z=[(x[i,2]) for i in range(self.size)]\n",
        "\n",
        "          meanx = statistics.mean(random_x)\n",
        "          meany = statistics.mean(random_y)\n",
        "          meanz = statistics.mean(random_z)\n",
        "\n",
        "          for i in range(self.size):\n",
        "            random_x[i] -= meanx\n",
        "            random_y[i] -= meany\n",
        "            random_z[i] -= meanz\n",
        "\n",
        "          random_d = [random_x, random_y, random_z]\n",
        "          print(random_d)\n",
        "\n",
        "        elif(topoMap == 'hexagonal'):\n",
        "          x, y = np.meshgrid(np.arange(0,self.N,1.0), np.arange(0,self.N,1.0)) #places mesh grid on data\n",
        "          for i in y:\n",
        "            for j in range(1,len(i),2):\n",
        "              i[j] += 0.5\n",
        "\n",
        "          self.c = np.hstack((y.flatten()[:, np.newaxis], #c is the topological distance of each node\n",
        "                           x.flatten()[:, np.newaxis])) # basically makes a 20x20 grid\n",
        "          #print(self.c)\n",
        "          fig = plt.figure(figsize=(10,10))\n",
        "          ax = plt.axes(projection=None)\n",
        "          ax.scatter(x, y, cmap=plt.cm.Spectral)\n",
        "        elif(topoMap == 'line'):\n",
        "          x = np.arange(N)\n",
        "          y = np.zeros(N)\n",
        "          self.c = np.vstack((x, y)).T\n",
        "        #find the center of the dataset\n",
        "        center = []\n",
        "        for i in random_d:\n",
        "          sum = 0\n",
        "          for j in i:\n",
        "            sum += j\n",
        "          center.append(sum/len(i))\n",
        "        #print(center)\n",
        "\n",
        "        #display the initialization\n",
        "        fig = plt.figure(figsize=(10,10))\n",
        "        ax = plt.axes(projection='3d')\n",
        "        #ax.scatter(random_x, random_y, random_z, cmap=plt.cm.Spectral)\n",
        "\n",
        "        teachers = []\n",
        "        #format the x,y,z cords in one array\n",
        "        random_d = np.array(random_d).T\n",
        "        print(random_d)\n",
        "        for i in range(len(random_d)):\n",
        "          teachers.append(random_d[i])\n",
        "        self.teachers = np.array(teachers)\n",
        "        self.n_teacher = self.teachers.shape[0]\n",
        "\n",
        "        if(initMethod == \"random\"):\n",
        "          #print(self.teachers.shape)\n",
        "          self.nodes = np.random.rand(self.N*self.N, self.teachers.shape[1]) #nodes is the actual point in space of the node\n",
        "          #print(self.nodes)\n",
        "            #adding the center of the data to every node\n",
        "          for node in self.nodes:\n",
        "            for i in range(len(node)):\n",
        "              node[i] += center[i]\n",
        "\n",
        "\n",
        "        elif(initMethod == \"pca\"):\n",
        "          U, s, VT = svd(teachers)\n",
        "          #print(VT)\n",
        "          VT = np.transpose(VT)  # this is just so we dont have to rewrite code cuz our PCA is perpendicular\n",
        "          #Rotation\n",
        "          V = np.transpose(VT)\n",
        "          V = V[0:2,:]\n",
        "          #print(\"\\nV:\", V)\n",
        "          Vnew = np.transpose(VT)\n",
        "          Vnew = Vnew[:,0:2]\n",
        "          #print(\"\\nVnew:\",Vnew)\n",
        "          self.W = np.hstack((y.flatten()[:, np.newaxis], # node network\n",
        "                           x.flatten()[:, np.newaxis]))\n",
        "          #print(self.W)\n",
        "          for i in range(0,self.map_nodes): # center the dataset\n",
        "            self.W[i][0] -= (self.N-1)/2\n",
        "            self.W[i][1] -= (self.N-1)/2\n",
        "          sum1 = 0\n",
        "          sum2 = 0\n",
        "          for i in range(0,self.map_nodes):\n",
        "            sum1 += self.W[i][0]\n",
        "            sum2 += self.W[i][1]\n",
        "          #print(sum1/self.map_nodes)\n",
        "          #print(sum2/self.map_nodes)\n",
        "          self.Wnew = np.dot(self.W,V) # dot product of first 2 rows of V and node network rotates the node network\n",
        "          # right now we do a dot product of 400 * 2 with 2 * 3\n",
        "          # try doing a dot product of 3 * 2 with 2 * 400\n",
        "          # so we need to rotate the self.W and dot that with VT giving us 3 * 400\n",
        "          # then rotate Wnew back 90 degrees to get 400 * 3\n",
        "          self.WT = np.transpose(self.W)\n",
        "          #self.Wnew = np.dot(Vnew,self.WT)\n",
        "          #self.Wnew = np.transpose(self.Wnew)\n",
        "          #print(\"\\nWnew:\",self.Wnew)\n",
        "          #print(np.shape(self.Wnew))\n",
        "\n",
        "          #Dilation\n",
        "          self.z = np.dot(self.teachers,Vnew) # dot product of first 2 cols of V and dataset represents rotated dataset\n",
        "          # this is to find the range to dilate our node network W\n",
        "          #print(\"\\nZ:\",self.z)\n",
        "          self.fixedz = np.dot(self.z,V)\n",
        "          ax.scatter(self.fixedz[:,0], self.fixedz[:,1], self.fixedz[:,2], color='yellow')\n",
        "          z1Min = min(self.z[:,0:1])[0]\n",
        "          z1Max = max(self.z[:,0:1])[0]\n",
        "          z2Min = min(self.z[:,1:2])[0]\n",
        "          z2Max = max(self.z[:,1:2])[0]\n",
        "          #print(z1Max)\n",
        "          #print(z1Min)\n",
        "          z1Range = (z1Max - z1Min)/(self.N)\n",
        "          z2Range = (z2Max - z2Min)/(self.N)\n",
        "          #print(z1Range)\n",
        "          dilateMatrix = [[z1Range, 0], [0,z2Range]]\n",
        "          #print(\"\\ntransformedMatrix:\", dilateMatrix)\n",
        "          scaledMatrix = np.dot(self.W,dilateMatrix) # scale our rotated node network by the dilated matrix\n",
        "          self.Wbrandnew = np.dot(scaledMatrix, V)\n",
        "          #self.Wbrandnew = np.transpose(self.Wbrandnew)\n",
        "          #print(\"\\nWbrandnew:\", self.Wbrandnew)\n",
        "          #print(np.shape(self.Wbrandnew))\n",
        "\n",
        "          #verify numerically that the PCA works\n",
        "          '''\n",
        "          print(max(np.dot(self.Wbrandnew, Vnew[:,0:1])))\n",
        "          print(\">\")\n",
        "          print(max(np.dot(self.fixedz, Vnew[:,0:1])))\n",
        "\n",
        "          print(min(np.dot(self.Wbrandnew, Vnew[:,1:2])))\n",
        "          print(\"<\")\n",
        "          print(min(np.dot(self.fixedz, Vnew[:,1:2])))\n",
        "          '''\n",
        "\n",
        "          #Display\n",
        "          ax.scatter(self.Wbrandnew[:,0],self.Wbrandnew[:,1],self.Wbrandnew[:,2], color='red')\n",
        "          #ax.set_xlim3d(-12, 15)\n",
        "          #ax.set_ylim3d(-1, 23)\n",
        "          #ax.set_zlim3d(-13, 16)\n",
        "          ax.view_init(0,90) # used for swissroll\n",
        "          #ax.view_init(90,180) # used for hyperbolic parabola\n",
        "          #ax.view_init(90,270) # used for s_curve\n",
        "          plt.show()\n",
        "\n",
        "          self.nodes = self.Wbrandnew\n",
        "          #print(self.nodes)\n",
        "          # look at the pca from the perspective of v3 and make sure the pca covers the entire projected dataset\n",
        "\n",
        "    def _best_matching_unit(self, teacher, k=1): # finds the BMU of a node\n",
        "        #compute all norms (eculidian distance)\n",
        "        norms = np.linalg.norm(self.nodes - teacher, axis=1) # takes the euclidian distance between a node and a teacher\n",
        "        if(k == 1):\n",
        "          bmu = np.argmin(norms) # argument with smallest distance from the teacher\n",
        "          return np.unravel_index(bmu,(self.N, self.N)) # returns the i and j of where the bmu is\n",
        "        else:\n",
        "          #TBD: use argpartition to optimize this (make it run faster)\n",
        "          arr = np.argsort(norms)[:2]\n",
        "          bmu1 = np.unravel_index(arr[0],(self.N, self.N))\n",
        "          bmu2 = np.unravel_index(arr[1],(self.N, self.N))\n",
        "          bmus = [bmu1,bmu2]\n",
        "          #print(bmus)\n",
        "          return bmus\n",
        "\n",
        "    def _neighborhood(self, t): #the \"gamma\" the percent of nodes that move the percent of the way to teacher\n",
        "        halflife = self.n_teacher/10\n",
        "        initial  = 1\n",
        "        final = 0.001\n",
        "        return max(initial*np.exp(-t/halflife), final) #the math part for matching/updating\n",
        "        #return 0.001\n",
        "\n",
        "    def _learning_ratio(self, t): #the \"alpha\" the percent of the way BMU moves to teacher\n",
        "        halflife = self.n_teacher/10\n",
        "        initial  = 0.5\n",
        "        final = 0.001\n",
        "        return max(initial*np.exp(-t/halflife), final)\n",
        "\n",
        "    def _learning_radius(self, t, d):\n",
        "        # d is distance from BMU\n",
        "        s = self._neighborhood(t)\n",
        "        return np.exp(-d**2/(2*s**2))\n",
        "\n",
        "    def train(self): #training algoirthm\n",
        "        index_arr = np.random.randint(len(self.teachers),size=len(self.teachers)) #first num is # of data points, second num is # of iterations\n",
        "        for i in range(len(index_arr)):\n",
        "            #print(self.teachers[index_arr[i]])\n",
        "            bmu = self._best_matching_unit(self.teachers[index_arr[i]])\n",
        "            d = np.linalg.norm(self.c - bmu, axis=1)\n",
        "            L = self._learning_ratio(i)\n",
        "            S = self._learning_radius(i, d)\n",
        "            self.nodes += L * S[:, np.newaxis] * (self.teachers[index_arr[i]] - self.nodes)\n",
        "        return self.nodes\n",
        "\n",
        "    def train_log(self): # training but only displays plots exponentially\n",
        "        power = 0\n",
        "        counter = 1\n",
        "        index_arr = np.random.randint(len(self.teachers),size=len(self.teachers)) #first num is # of data points, second num is # of iterations\n",
        "        for i in range(len(index_arr)):\n",
        "            bmu = self._best_matching_unit(self.teachers[index_arr[i]])\n",
        "            #print(self.nodes)\n",
        "            d = np.linalg.norm(self.c - bmu, axis=1)\n",
        "            #print(\"D: \", d)\n",
        "            L = self._learning_ratio(i)\n",
        "            S = self._learning_radius(i, d)\n",
        "            #print(\"S: \", S)\n",
        "            self.nodes += L * S[:, np.newaxis] * (self.teachers[index_arr[i]] - self.nodes)\n",
        "            if(i % counter == 0):\n",
        "              fig = plt.figure(figsize=(10,10))\n",
        "              ax = plt.axes(projection='3d')\n",
        "              print(counter)\n",
        "              print(\"BMU:\", self.nodes[bmu[0]*self.N + bmu[1]])\n",
        "              #self.plot_dataset(fig, ax)\n",
        "              #self.plot_nodes(fig, ax)\n",
        "              self.edge_map()\n",
        "              plt.show()\n",
        "              self.u_matrix()\n",
        "              power += 1\n",
        "              counter = 2 ** power\n",
        "        return self.nodes\n",
        "\n",
        "    #first num is # of data points, second num is # of iterations\n",
        "        for i in range(len(indexArr)):\n",
        "            bmu = self._best_matching_unit(self.teachers[indexArr[i]])\n",
        "            d = np.linalg.norm(self.c - bmu, axis=1)\n",
        "            L = self._learning_ratio(i)\n",
        "            S = self._learning_radius(i, d)\n",
        "            self.nodes += L * S[:, np.newaxis] * (self.teachers[indexArr[i]] - self.nodes)\n",
        "            for index in indexList:\n",
        "              if(index == i):\n",
        "                print(index)\n",
        "                self.edge_map()\n",
        "        return self.nodes\n",
        "\n",
        "    def u_matrix(self): # shows distances between points on the SOM || higher value means farther distance and less dense SOM, basically inverse heatmap\n",
        "        uMatrixMap = np.zeros([self.N,self.N]) #2d array of 0s\n",
        "        #loop through self.c (topological map)\n",
        "        for i in range(0, self.map_nodes):\n",
        "          adjacent = []\n",
        "          for j in range(0, self.map_nodes):\n",
        "            difference = abs(self.c[i] - self.c[j])\n",
        "            #print(difference)\n",
        "            if(self.topoMap == \"square\"):\n",
        "              if(0 in difference and 1 in difference):\n",
        "                #print(self.nodes[i])\n",
        "                #print(self.nodes[j])\n",
        "                distance = np.linalg.norm(self.nodes[i] - self.nodes[j], ord=2)\n",
        "                adjacent.append(distance)\n",
        "                #print(distance)\n",
        "                # self.c[i] - self.c[j] will return a point like [0,0]\n",
        "                # ex. [0,0] - [0,1] = [0,1] [0,-1] [1,0] [-1,0]\n",
        "                # ex. [7,8] - [7,7] = [0,1]\n",
        "                # to check for adjacency, check if the difference includes a 0 in one position and either a 1 or -1 in the other\n",
        "                # once we have that, find the x,y,z coords of self.nodes[i] and self.nodes[j] and use euclidian distance formula to find distance\n",
        "                # put that distance into our distance map\n",
        "            elif(self.topoMap == \"hexagonal\"):\n",
        "              if((0 in difference and 1 in difference) or (1 in difference and 0.5 in difference)):   #first part is adjacency for nodes above and below and second part is for adjacency for nodes to the left and right\n",
        "                #print(difference)\n",
        "                distance = np.linalg.norm(self.nodes[i] - self.nodes[j], ord=2)\n",
        "                adjacent.append(distance)\n",
        "            elif(self.topoMap == \"line\"):\n",
        "              if(1 in difference):\n",
        "                distance = np.linalg.norm(self.nodes[i] - self.nodes[j], ord=2)\n",
        "                adjacent.append(distance)\n",
        "          sum = 0\n",
        "          #print(adjacent)\n",
        "          for distance in adjacent:\n",
        "            sum += distance\n",
        "          avg = sum/len(adjacent)\n",
        "          x = i // self.N\n",
        "          y = i % self.N\n",
        "          uMatrixMap[x][y] = avg\n",
        "        #print(uMatrixMap)\n",
        "        figure = plt.figure()\n",
        "        if(self.topoMap == 'square' or self.topoMap == 'line'):\n",
        "          plt.pcolor(uMatrixMap.T, cmap=\"viridis\")\n",
        "        elif(self.topoMap == 'hexagonal'):\n",
        "          ax = plt.gca()\n",
        "          ax.cla()\n",
        "          ax.set_xlim(-1,self.N)\n",
        "          ax.set_ylim(-1,self.N)\n",
        "          ax.set_aspect('equal')\n",
        "\n",
        "          uMatrixMap[:,:] /= np.amax(uMatrixMap) # convert the map to be between 0->1 by dividing each element by the highest value\n",
        "          #print(uMatrixMap)\n",
        "          viridisMap = cm.viridis(uMatrixMap[:,:])\n",
        "          #print(viridisMap)\n",
        "          colorMap = [] # holds the hex colors of each value in uMatrixMap\n",
        "          for a in viridisMap:\n",
        "            temp = []\n",
        "            for b in a:\n",
        "              temp.append(colors.rgb2hex(b))\n",
        "            colorMap.append(temp)\n",
        "          #print(colorMap)\n",
        "\n",
        "          for xcoord in range(self.N): # creates the hexagons\n",
        "            for ycoord in range(self.N):\n",
        "              if(xcoord % 2 == 1):\n",
        "                hex = patches.RegularPolygon((xcoord, ycoord+0.5), numVertices=6, radius=2. / 3.,\n",
        "                          orientation=np.radians(30),\n",
        "                          facecolor=colorMap[xcoord][ycoord], alpha=1, edgecolor='k')\n",
        "                ax.add_patch(hex)\n",
        "              else:\n",
        "                hex = patches.RegularPolygon((xcoord, ycoord), numVertices=6, radius=2. / 3.,\n",
        "                          orientation=np.radians(30),\n",
        "                          facecolor=colorMap[xcoord][ycoord], alpha=1, edgecolor='k')\n",
        "                ax.add_patch(hex)\n",
        "        #plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "    def edge_map(self, color=False): # shows the connection between nodes\n",
        "        fig = plt.figure(figsize=(10,10))\n",
        "        ax = plt.axes(projection='3d')\n",
        "        self.plot_nodes(fig, ax, color=color)\n",
        "        for i in range(0, self.map_nodes):\n",
        "          adjacent = []\n",
        "          for j in range(0, self.map_nodes):\n",
        "            difference = abs(self.c[i] - self.c[j])\n",
        "            if(self.topoMap == \"square\"):\n",
        "              if(0 in difference and 1 in difference):\n",
        "                adjacent.append(j) # appends the index of the adjacent node\n",
        "            elif(self.topoMap == \"hexagonal\"):\n",
        "              if((0 in difference and 1 in difference) or (1 in difference and 0.5 in difference)):\n",
        "                adjacent.append(j) # appends the index of the adjacent node\n",
        "            elif(self.topoMap == \"line\"):\n",
        "              if(1 in difference):\n",
        "                adjacent.append(j)\n",
        "          for k in range(len(adjacent)):\n",
        "            # takes the x,y,z value of each adjacent node and the ith node to form a pair of points\n",
        "            x = np.array((self.nodes[i][0], self.nodes[adjacent[k]][0]))\n",
        "            y = np.array((self.nodes[i][1], self.nodes[adjacent[k]][1]))\n",
        "            z = np.array((self.nodes[i][2], self.nodes[adjacent[k]][2]))\n",
        "            ax.plot(x,y,z,c='black',alpha=0.5) # plots the edges between the pair of points\n",
        "        #ax.set_xlim3d([-99, -97])\n",
        "        #ax.set_ylim3d([39, 43])\n",
        "        #ax.set_zlim3d([0, 1])\n",
        "        plt.show() # displays every node as well as the adjacent edges between each node\n",
        "\n",
        "    def button_plot(self): # shows the \"breaks\" in the data\n",
        "        closest = [[] for _ in range(0,self.map_nodes)]\n",
        "        for i in range(0,len(self.teachers)):\n",
        "          index = 0\n",
        "          min_distance = 10000000\n",
        "          bmu = self._best_matching_unit(self.teachers[i]) # finds the BMU for each data point\n",
        "          current_distance = np.linalg.norm(self.teachers[i] - self.nodes[bmu[0]*self.N + bmu[1]], ord=2)\n",
        "          if(current_distance < min_distance): # find the data point that is closest to a given node\n",
        "            min_distance = current_distance\n",
        "            index = bmu[0]*self.N + bmu[1]\n",
        "          closest[index].append(i) # add data point to the list\n",
        "        ax = plt.gca()\n",
        "        ax.cla()\n",
        "        if(self.topoMap == 'square'):\n",
        "          for i in range(0,self.map_nodes): # creates the empty node images\n",
        "            circle = plt.Circle((i//self.N, i%self.N), 0.5, color='black', fill=False)\n",
        "            ax.set_xlim((-1, self.N))\n",
        "            ax.set_ylim((-1, self.N))\n",
        "            ax.add_patch(circle)\n",
        "          for i in range(len(closest)):\n",
        "            for j in range(len(closest[i])):\n",
        "              random_theta = np.random.rand() * 2 * np.pi\n",
        "              random_r = np.random.rand() * 0.45\n",
        "              x = (random_r * np.cos(random_theta)) + i // self.N\n",
        "              y = (random_r * np.sin(random_theta)) + i % self.N\n",
        "              ax.plot(x,y,'o',markersize=3)\n",
        "          plt.show()\n",
        "        elif(self.topoMap == 'line'):\n",
        "          ax.set_xlim((-1, self.N))\n",
        "          ax.set_ylim((-1, 1))\n",
        "          for i in range(0, self.map_nodes):\n",
        "            circle = plt.Circle((i, 0), 0.5, color='black', fill=False)\n",
        "            ax.add_patch(circle)\n",
        "          for i in range(len(closest)):\n",
        "            for j in range(len(closest[i])):\n",
        "              random_theta = np.random.rand() * 2 * np.pi\n",
        "              random_r = np.random.rand() * 0.45\n",
        "              x = (random_r * np.cos(random_theta)) + i\n",
        "              y = (random_r * np.sin(random_theta))\n",
        "              ax.plot(x,y,'o',markersize=3)\n",
        "          plt.show()\n",
        "        elif(self.topoMap == 'hexagonal'):\n",
        "          shift = True\n",
        "          for i in range(0,self.map_nodes): # creates the empty node images\n",
        "            if(i%self.N == 0):\n",
        "              if(shift):\n",
        "                shift = False\n",
        "              else:\n",
        "                shift = True\n",
        "            if(shift):\n",
        "              circle = plt.Circle((i//self.N, (i%self.N) + 0.5), 0.5, color='black', fill=False)\n",
        "              ax.set_xlim((-1, self.N))\n",
        "              ax.set_ylim((-1, self.N+1))\n",
        "              ax.add_patch(circle)\n",
        "            else:\n",
        "              circle = plt.Circle((i//self.N, i%self.N), 0.5, color='black', fill=False)\n",
        "              ax.set_xlim((-1, self.N))\n",
        "              ax.set_ylim((-1, self.N+1))\n",
        "              ax.add_patch(circle)\n",
        "          shift = True\n",
        "          for i in range(len(closest)):\n",
        "            if(i%self.N == 0):\n",
        "              if(shift):\n",
        "                shift = False\n",
        "              else:\n",
        "                shift = True\n",
        "            for j in range(len(closest[i])):\n",
        "              random_theta = np.random.rand() * 2 * np.pi\n",
        "              random_r = np.random.rand() * 0.45\n",
        "              if(shift):\n",
        "                x = (random_r * np.cos(random_theta)) + i // self.N\n",
        "                y = (random_r * np.sin(random_theta)) + i % self.N + 0.5\n",
        "              else:\n",
        "                x = (random_r * np.cos(random_theta)) + i // self.N\n",
        "                y = (random_r * np.sin(random_theta)) + i % self.N\n",
        "              ax.plot(x,y,'o',markersize=3)\n",
        "          plt.show()\n",
        "        #print(closest)\n",
        "\n",
        "    def plot_dataset(self, figure=plt.figure(figsize=(10,10)), axes=plt.axes(projection='3d')): # plots all of the nodes in the SOM\n",
        "        x_ints=[i[0] for i in self.teachers]\n",
        "        y_ints=[i[1] for i in self.teachers]\n",
        "        z_ints=[i[2] for i in self.teachers]\n",
        "        fig = figure\n",
        "        ax = axes\n",
        "        ax.scatter(x_ints,y_ints,z_ints, cmap=plt.cm.Spectral)\n",
        "        #plt.show()\n",
        "\n",
        "    def plot_nodes(self, figure=plt.figure(figsize=(10,10)), axes=plt.axes(projection='3d'), color=False): # plots all of the nodes in the SOM\n",
        "        x_ints=[i[0] for i in self.nodes]\n",
        "        y_ints=[i[1] for i in self.nodes]\n",
        "        z_ints=[i[2] for i in self.nodes]\n",
        "        fig = figure\n",
        "        ax = axes\n",
        "        if(color == False):\n",
        "          ax.scatter(x_ints,y_ints,z_ints,c='orange')\n",
        "        else:\n",
        "          colors = []\n",
        "          for point in self.nodes:\n",
        "            colors.append([point[3], point[4], point[5]]) # i[3] is red, i[4] is green, and i[5] is blue\n",
        "          ax.scatter(x_ints,y_ints,z_ints,c=colors)\n",
        "        #plt.show()\n",
        "\n",
        "    def quant_error(self, teachers): # Quantization error\n",
        "        distance_sum = 0\n",
        "        for i in range(0,len(teachers)):\n",
        "          min_distance = 10000000\n",
        "          bmu = self._best_matching_unit(teachers[i]) # finds the BMU for each data point\n",
        "          current_distance = np.linalg.norm(self.teachers[i] - self.nodes[bmu[0]*self.N + bmu[1]], ord=2)\n",
        "          if(current_distance < min_distance): # find the data point that is closest to a given node\n",
        "            min_distance = current_distance\n",
        "          distance_sum += min_distance # adds the distance of each data point that is closest to a given node\n",
        "        error = distance_sum/len(teachers) # finds the average distance\n",
        "        return error\n",
        "\n",
        "    def topo_error(self, teachers): # Topographic Error\n",
        "        error_sum = 0\n",
        "        for i in range(0, len(teachers)):\n",
        "          bmus = self._best_matching_unit(teachers[i], k=2) # finds the two closest BMUs for each data point\n",
        "          difference_x = bmus[0][0] - bmus[1][0]\n",
        "          difference_y = bmus[0][1] - bmus[1][1]\n",
        "          if((difference_x == 0 and difference_y == -1) or (difference_x == 0 and difference_y == 1) or (difference_x == 1 and difference_y == 0) or (difference_x == -1 and difference_y == 0)): # checks if BMUs are next to each other\n",
        "            error_sum += 0\n",
        "          else:\n",
        "            error_sum += 1\n",
        "        error = error_sum/len(teachers)\n",
        "        return error\n",
        "\n",
        "    def error_entropy(self):\n",
        "        closest = np.zeros(self.map_nodes)\n",
        "        size = np.zeros(self.map_nodes)\n",
        "        for i in range(0,len(self.teachers)):\n",
        "          index = 0\n",
        "          min_distance = 10000000\n",
        "          bmu = self._best_matching_unit(self.teachers[i]) # finds the BMU for each data point\n",
        "          current_distance = np.linalg.norm(self.teachers[i] - self.nodes[bmu[0]*self.N + bmu[1]], ord=2)\n",
        "          if(current_distance < min_distance): # find the data point that is closest to a given node\n",
        "            min_distance = current_distance\n",
        "            index = bmu[0]*self.N + bmu[1]\n",
        "          closest[index] = closest[index] + (distance(self.teachers[i], self.nodes[index])) # add data point to the list\n",
        "          size[index] = size[index] + 1\n",
        "        E = 0\n",
        "        entropy_error = 0\n",
        "\n",
        "        for i in range(0, len(closest)):\n",
        "            E = E + closest[i]\n",
        "        for i in range(0, len(closest)):\n",
        "            e = closest[i] / E\n",
        "            entropy_error = entropy_error + e + math.log(e, 2)\n",
        "        # lower better\n",
        "        return -entropy_error\n",
        "\n",
        "    def trustworthiness(self, teachers, k): # Trustworthiness (scrapped for later when we have more manpower)\n",
        "        errors = 0\n",
        "        for i in range(0, len(teachers)):\n",
        "          setA = [] # k nearest data points for each data point\n",
        "          for j in range(0, len(teachers)):\n",
        "            distance = np.linalg.norm(self.teachers[i] - self.teachers[j])\n",
        "            setA.append([distance,j])\n",
        "          setA.sort()\n",
        "          setA = setA[1:k+1]\n",
        "          norms = np.linalg.norm(self.nodes - teachers[i], axis=1)\n",
        "          bmu = np.argmin(norms)\n",
        "          #print(bmu)\n",
        "          setB = [] # k nearest data points for the BMU\n",
        "          for j in range(0, len(teachers)):\n",
        "             distance = np.linalg.norm(self.nodes[bmu] - self.teachers[j])\n",
        "             setB.append([distance, j])\n",
        "          setB.sort()\n",
        "          setB = setB[1:k+1]\n",
        "          for j in range(0, len(setA)):\n",
        "            print(setA[j][1], setB[j][1])\n",
        "          #print(errors)\n",
        "          #for j in range(0,len(setB)):\n",
        "            #print(setA[j], setB[j])\n",
        "          print(i)\n",
        "        return errors\n",
        "\n",
        "    def grader(self, iterationNumber): #grader function\n",
        "        quantError = []\n",
        "        topoError = []\n",
        "        for i in range(iterationNumber): #for # of iterations\n",
        "          som = SOM(dataset=self.dataset, topoMap=self.topoMap, initMethod=self.initMethod, N=self.N, size=self.size, seed=self.seed) #create/initialize ur som\n",
        "          som.train() #train ur som\n",
        "          som.edge_map() #visualize som with edges\n",
        "          som.u_matrix()\n",
        "          #som.button_plot()\n",
        "\n",
        "          quant = som.quant_error(som.teachers)\n",
        "          topo = som.topo_error(som.teachers)\n",
        "          quantError.append(quant) #store quant error in list\n",
        "          topoError.append(topo) #store topo error in list\n",
        "          #print iteration number\n",
        "          #print(\"Iteration: \" + str(i) + \", Quantization Error: \" + str(quant) + \", Topographic Error: \" + str(topo))\n",
        "          #print quant and topo error\n",
        "\n",
        "        # always good to use variables so we dont have to recalculate, saves on run time\n",
        "        quantMean = statistics.mean(quantError)\n",
        "        quantStdev = statistics.stdev(quantError)\n",
        "        quantRange = max(quantError) - min(quantError)\n",
        "        topoMean = statistics.mean(topoError)\n",
        "        topoStdev = statistics.stdev(topoError)\n",
        "        topoRange = max(topoError) - min(topoError)\n",
        "\n",
        "        # grouped the statistics by its error function so we can easily compare within each error function\n",
        "        '''\n",
        "        print(\"QuantError List:\", quantError) #print quanterror list\n",
        "        print(\"Quant Mean:\", quantMean) #print and calculate mean\n",
        "        print(\"Quant stdev:\", quantStdev) #print and calculate std deviation\n",
        "        print(\"Quant Range:\", quantRange) #print and calculate the range\n",
        "\n",
        "        print(\"\\nTopoError List:\", topoError) #print topoerror list\n",
        "        print(\"Topo Mean:\", topoMean) #print and calculate mean\n",
        "        print(\"Topo stdev:\", topoStdev) #print and calculate std deviation\n",
        "        print(\"Topo Range:\", topoRange) #print and calculate the range\n",
        "        '''\n",
        "\n",
        "        # put the final statistics at the end so we can easily compare between different error functions\n",
        "        finalQuantErrorList = [\"Quantitative Error:\", (\"Mean\", quantMean), (\"Standard Deviation\", quantStdev), (\"Range\", quantRange)]\n",
        "        finalTopoErrorList = [\"Topological Error:\", (\"Mean\", topoMean), (\"Standard Deviation\", topoStdev), (\"Range\", topoRange)]\n",
        "        error_list = []\n",
        "        error_list.append(finalQuantErrorList)\n",
        "        error_list.append(finalTopoErrorList)\n",
        "        #print(error_list)\n",
        "        return error_list\n",
        "\n",
        "    def grader_to_file(self, file_name, iterationNumber): #grader function for files\n",
        "        quantError = []\n",
        "        topoError = []\n",
        "        figureList = []\n",
        "        for i in range(iterationNumber): #for # of iterations\n",
        "          som = SOM(dataset=self.dataset, initMethod=self.initMethod, N=self.N, size=self.size, seed=self.seed) #create/initialize ur som\n",
        "          som.train() #train ur som\n",
        "          figureList.append(som.edge_map()) #visualize som with edges\n",
        "          figureList.append(som.u_matrix())\n",
        "          figureList.append(som.button_plot())\n",
        "\n",
        "          quant = som.quant_error(som.teachers)\n",
        "          topo = som.topo_error(som.teachers)\n",
        "          quantError.append(quant) #store quant error in list\n",
        "          topoError.append(topo) #store topo error in list\n",
        "          #print iteration number\n",
        "          #print(\"Iteration: \" + str(i) + \", Quantization Error: \" + str(quant) + \", Topographic Error: \" + str(topo))\n",
        "          #print quant and topo error\n",
        "\n",
        "        p = PdfPages(file_name)\n",
        "        for fig in figureList:\n",
        "            fig.savefig(p, format='pdf')\n",
        "        p.close()\n",
        "\n",
        "        # always good to use variables so we dont have to recalculate, saves on run time\n",
        "        quantMean = statistics.mean(quantError)\n",
        "        quantStdev = statistics.stdev(quantError)\n",
        "        quantRange = max(quantError) - min(quantError)\n",
        "        topoMean = statistics.mean(topoError)\n",
        "        topoStdev = statistics.stdev(topoError)\n",
        "        topoRange = max(topoError) - min(topoError)\n",
        "\n",
        "        # grouped the statistics by its error function so we can easily compare within each error function\n",
        "        '''\n",
        "        print(\"QuantError List:\", quantError) #print quanterror list\n",
        "        print(\"Quant Mean:\", quantMean) #print and calculate mean\n",
        "        print(\"Quant stdev:\", quantStdev) #print and calculate std deviation\n",
        "        print(\"Quant Range:\", quantRange) #print and calculate the range\n",
        "\n",
        "        print(\"\\nTopoError List:\", topoError) #print topoerror list\n",
        "        print(\"Topo Mean:\", topoMean) #print and calculate mean\n",
        "        print(\"Topo stdev:\", topoStdev) #print and calculate std deviation\n",
        "        print(\"Topo Range:\", topoRange) #print and calculate the range\n",
        "        '''\n",
        "\n",
        "        # put the final statistics at the end so we can easily compare between different error functions\n",
        "        finalQuantErrorList = [\"Quantitative Error:\", (\"Mean\", quantMean), (\"Standard Deviation\", quantStdev), (\"Range\", quantRange)]\n",
        "        finalTopoErrorList = [\"Topological Error:\", (\"Mean\", topoMean), (\"Standard Deviation\", topoStdev), (\"Range\", topoRange)]\n",
        "        error_list = []\n",
        "        error_list.append(finalQuantErrorList)\n",
        "        error_list.append(finalTopoErrorList)\n",
        "        #print(error_list)\n",
        "\n",
        "        f = open(file_name, \"a\")\n",
        "        f.write(\"Hello\")\n",
        "        for elist in error_list:\n",
        "          for element in elist:\n",
        "            f.write(''.join(str(element)))\n",
        "        f.close()\n",
        "\n",
        "        return error_list\n",
        "\n",
        "    def equation_plane(self, x1, y1, z1, x2, y2, z2, x3, y3, z3):\n",
        "      a1 = x2 - x1\n",
        "      b1 = y2 - y1\n",
        "      c1 = z2 - z1\n",
        "      a2 = x3 - x1\n",
        "      b2 = y3 - y1\n",
        "      c2 = z3 - z1\n",
        "      a = b1 * c2 - b2 * c1\n",
        "      b = a2 * c1 - a1 * c2\n",
        "      c = a1 * b2 - b1 * a2\n",
        "      d = (- a * x1 - b * y1 - c * z1)\n",
        "\n",
        "      return (a, b, c, d)\n",
        "\n",
        "\n",
        "    def plane_intersect(self, a, b):\n",
        "      \"\"\"\n",
        "      a, b   4-tuples/lists\n",
        "            Ax + By +Cz + D = 0\n",
        "            A,B,C,D in order\n",
        "\n",
        "      output: 2 points on line of intersection, np.arrays, shape (3,)\n",
        "      \"\"\"\n",
        "      a_vec, b_vec = np.array(a[:3]), np.array(b[:3])\n",
        "\n",
        "      aXb_vec = np.cross(a_vec, b_vec)\n",
        "\n",
        "      A = np.array([a_vec, b_vec, aXb_vec])\n",
        "      d = np.array([-a[3], -b[3], 0.]).reshape(3,1)\n",
        "\n",
        "  # could add np.linalg.det(A) == 0 test to prevent linalg.solve throwing error\n",
        "\n",
        "      p_inter = np.linalg.solve(A, d).T\n",
        "\n",
        "      return (p_inter[0], (p_inter + aXb_vec)[0])\n",
        "\n",
        "\n",
        "    def intersections(self):\n",
        "      planes = []\n",
        "      for i in range(self.N**2):\n",
        "        store_plane_index = [i]\n",
        "        store_plane_index_2 = [i]\n",
        "        found_plane_1 = False\n",
        "        found_plane_2 = False\n",
        "        for j in range(self.N**2):\n",
        "          distance = self.c[i] - self.c[j]\n",
        "\n",
        "          # if node j is above, and diagnal right, add to the first triangle; if node j is to the right and diagnal right, add to the second triangle\n",
        "          if (distance[0] == 0 and distance[1] == -1): # above\n",
        "            store_plane_index.insert(1, j)\n",
        "          if (distance[0] == -1 and distance[1] == -1): # diagnal right\n",
        "            store_plane_index.insert(2, j)\n",
        "            store_plane_index_2.insert(2, j)\n",
        "          if (distance[0] == -1 and distance[1] == 0): # right\n",
        "            store_plane_index_2.insert(1, j)\n",
        "\n",
        "          #print(store_plane_index)\n",
        "\n",
        "          if len(store_plane_index) == 3: # if there are enough nodes to make a proper plane\n",
        "            store_plane = []\n",
        "            for k in range(len(store_plane_index)):\n",
        "              xyz = (self.nodes[store_plane_index[k]][0], self.nodes[store_plane_index[k]][1], self.nodes[store_plane_index[k]][2]) # find xyz coordinates\n",
        "              #print(xyz)\n",
        "              store_plane.extend(xyz) # add xyz coordinates to store_plane\n",
        "            planes.append(store_plane)\n",
        "            found_plane_1 = True\n",
        "\n",
        "          if len(store_plane_index_2) == 3: # if there are enough nodes to make a proper plane\n",
        "            store_plane = []\n",
        "            for k in range(len(store_plane_index_2)):\n",
        "              xyz = (self.nodes[store_plane_index_2[k]][0], self.nodes[store_plane_index_2[k]][1], self.nodes[store_plane_index_2[k]][2]) # find xyz coordinates\n",
        "              #print(xyz)\n",
        "              store_plane.extend(xyz) # add xyz coordinates to store_plane\n",
        "            planes.append(store_plane)\n",
        "            found_plane_2 = True\n",
        "\n",
        "          if(found_plane_1 and found_plane_2):\n",
        "            break\n",
        "\n",
        "\n",
        "      print(planes) # all planes\n",
        "      print(len(planes))\n",
        "      for points in planes:\n",
        "        p0 = [points[0], points[1], points[2]]\n",
        "        p1 = [points[3], points[4], points[5]]\n",
        "        p2 = [points[6], points[7], points[8]]\n",
        "        x0, y0, z0 = p0\n",
        "        x1, y1, z1 = p1\n",
        "        x2, y2, z2 = p2\n",
        "\n",
        "        ux, uy, uz = u = [x1-x0, y1-y0, z1-z0]\n",
        "        vx, vy, vz = v = [x2-x0, y2-y0, z2-z0]\n",
        "\n",
        "        u_cross_v = [uy*vz-uz*vy, uz*vx-ux*vz, ux*vy-uy*vx]\n",
        "\n",
        "        point  = np.array(p0)\n",
        "        normal = np.array(u_cross_v)\n",
        "\n",
        "        d = -point.dot(normal)\n",
        "\n",
        "        xx, yy = np.meshgrid(range(10), range(10))\n",
        "\n",
        "        z = (-normal[0] * xx - normal[1] * yy - d) * 1. / normal[2]\n",
        "\n",
        "        # plot the surface\n",
        "        plt3d = plt.axes(projection='3d')\n",
        "        plt3d.plot_surface(xx, yy, z)\n",
        "        plt.show()\n",
        "\n",
        "      intersects = []\n",
        "      counter = 0\n",
        "      breakcounter1 = 0\n",
        "      breakcounter2 = 0\n",
        "      for i in planes:\n",
        "        a = som.equation_plane(*i) #finding equations of planes i and j\n",
        "        print(a)\n",
        "\n",
        "        vert_line_i = Line.from_points(i[0:3], i[3:6]) #find lines for all 3 lines making up plane i\n",
        "        horiz_line_i = Line.from_points(i[0:3], i[6:9])\n",
        "        diag_line_i = Line.from_points(i[3:6], i[6:9])\n",
        "        list_line_i = [vert_line_i, horiz_line_i, diag_line_i]\n",
        "\n",
        "        for j in planes:\n",
        "          if i == j: # not looking at the same 2 planes\n",
        "            continue\n",
        "\n",
        "          b = som.equation_plane(*j)\n",
        "          print(b)\n",
        "          intersects_i = []\n",
        "          intersects_j = []\n",
        "          #print(j)\n",
        "          vert_line_j = Line.from_points(j[0:3], j[3:6]) #find lines for all 3 lines making up plane j\n",
        "          horiz_line_j = Line.from_points(j[0:3], j[6:9])\n",
        "          diag_line_j = Line.from_points(j[3:6], j[6:9])\n",
        "          list_line_j = [vert_line_j, horiz_line_j, diag_line_j]\n",
        "\n",
        "          try:\n",
        "            intersect_points = som.plane_intersect(a, b) #find points along the line of intersection of the planes\n",
        "            #print(intersect_points)\n",
        "            #intersects.append(intersect_points)\n",
        "\n",
        "            line_of_intersection = Line.from_points(intersect_points[0],intersect_points[1])\n",
        "            #print(line_of_intersection)\n",
        "          except:\n",
        "            #print(\"a\")\n",
        "            continue\n",
        "\n",
        "          ixmax = max(i[::3])\n",
        "          ixmin = min(i[::3])\n",
        "          iymax = max(i[1::3])\n",
        "          iymin = min(i[1::3])\n",
        "          izmax = max(i[2::3])\n",
        "          izmin = min(i[2::3])\n",
        "\n",
        "\n",
        "\n",
        "          for k in list_line_i: #test for intersection between each line making up plane i and the line of intersection to find the points of intersection\n",
        "            try:\n",
        "              point_intersection = line_of_intersection.intersect_line(k)\n",
        "              if(point_intersection[0] > ixmin and point_intersection[0] < ixmax and point_intersection[1] > iymin and point_intersection[1] < iymax and point_intersection[2] > izmin and point_intersection[2] < izmax):\n",
        "                #print(point_intersection)\n",
        "                intersects_i.append(point_intersection.tolist())\n",
        "            except:\n",
        "              #print(\"b\")\n",
        "              pass\n",
        "          if(len(intersects_i) < 2):\n",
        "            breakcounter1 += 1\n",
        "            continue\n",
        "\n",
        "          jxmax = max(j[::3])\n",
        "          jxmin = min(j[::3])\n",
        "          jymax = max(j[1::3])\n",
        "          jymin = min(j[1::3])\n",
        "          jzmax = max(j[2::3])\n",
        "          jzmin = min(j[2::3])\n",
        "\n",
        "          for k in list_line_j: #test for intersection between each line making up plane i and the line of intersection to find the points of intersection\n",
        "            try:\n",
        "              point_intersection = line_of_intersection.intersect_line(k)\n",
        "              if(point_intersection[0] > jxmin and point_intersection[0] < jxmax and point_intersection[1] > jymin and point_intersection[1] < jymax and point_intersection[2] > jzmin and point_intersection[2] < jzmax):\n",
        "                #print(point_intersection)\n",
        "                intersects_j.append(point_intersection.tolist())\n",
        "            except:\n",
        "              #print(\"b\")\n",
        "              pass\n",
        "          if(len(intersects_j) < 2):\n",
        "            breakcounter2 += 1\n",
        "            continue\n",
        "\n",
        "          print(intersects_i)\n",
        "          xmax = max(intersects_i[0][0], intersects_i[1][0])\n",
        "          xmin = min(intersects_i[0][0], intersects_i[1][0])\n",
        "          ymax = max(intersects_i[0][1], intersects_i[1][1])\n",
        "          ymin = min(intersects_i[0][1], intersects_i[1][1])\n",
        "          zmax = max(intersects_i[0][2], intersects_i[1][2])\n",
        "          zmin = min(intersects_i[0][2], intersects_i[1][2])\n",
        "\n",
        "          for k in intersects_j:\n",
        "            if(k[0] > xmin and k[0] < xmax and k[1] > ymin and k[1] < ymax and k[2] > zmin and k[2] < zmax):\n",
        "                counter += 1\n",
        "                break\n",
        "\n",
        "      print(counter)\n",
        "\n",
        "    def areas(self):\n",
        "        #print(self.nodes)\n",
        "        areas = np.zeros((self.N - 1, self.N - 1))\n",
        "        for i in range(self.N - 1):\n",
        "          for j in range(self.N - 1):\n",
        "            p1 = i*self.N + j\n",
        "            p2 = i*self.N + j + 1\n",
        "            p3 = i*self.N + j + self.N\n",
        "            p4 = i*self.N + j + 1 + self.N\n",
        "            d1 = distance(self.nodes[p1], self.nodes[p2])\n",
        "            d2 = distance(self.nodes[p1], self.nodes[p3])\n",
        "            d3 = distance(self.nodes[p1], self.nodes[p4])\n",
        "            d4 = distance(self.nodes[p2], self.nodes[p4])\n",
        "            d5 = distance(self.nodes[p3], self.nodes[p4])\n",
        "            areas[i][j] = heron(d1, d3, d4) + heron(d2, d3, d5)\n",
        "        #print(areas)\n",
        "        return areas\n",
        "\n",
        "    def astar(self, maze, start, end):\n",
        "        \"\"\"Returns a list of tuples as a path from the given start to the given end in the given maze\"\"\"\n",
        "\n",
        "        # Create start and end node\n",
        "        start_node = Node(None, start)\n",
        "        start_node.g = start_node.h = start_node.f = 0\n",
        "        end_node = Node(None, end)\n",
        "        end_node.g = end_node.h = end_node.f = 0\n",
        "\n",
        "        # Initialize both open and closed list\n",
        "        open_list = []\n",
        "        closed_list = []\n",
        "\n",
        "        # Add the start node\n",
        "        open_list.append(start_node)\n",
        "\n",
        "        # Loop until you find the end\n",
        "        while len(open_list) > 0:\n",
        "\n",
        "            # Get the current node\n",
        "            current_node = open_list[0]\n",
        "            current_index = 0\n",
        "            for index, item in enumerate(open_list):\n",
        "                if item.f < current_node.f:\n",
        "                    current_node = item\n",
        "                    current_index = index\n",
        "\n",
        "            # Pop current off open list, add to closed list\n",
        "            open_list.pop(current_index)\n",
        "            closed_list.append(current_node)\n",
        "\n",
        "            # Found the goal\n",
        "            if current_node == end_node:\n",
        "                path = []\n",
        "                current = current_node\n",
        "                while current is not None:\n",
        "                    path.append(current.position)\n",
        "                    current = current.parent\n",
        "                return path[::-1] # Return reversed path\n",
        "\n",
        "            # Generate children\n",
        "            children = []\n",
        "            for new_position in [(0, -1), (0, 1), (-1, 0), (1, 0)]: # Adjacent squares\n",
        "\n",
        "                # Get node position\n",
        "                node_position = (current_node.position[0] + new_position[0], current_node.position[1] + new_position[1])\n",
        "\n",
        "                # Make sure within range\n",
        "                if node_position[0] > (len(maze) - 1) or node_position[0] < 0 or node_position[1] > (len(maze[len(maze)-1]) -1) or node_position[1] < 0:\n",
        "                    continue\n",
        "\n",
        "                # Make sure walkable terrain\n",
        "                if maze[node_position[0]][node_position[1]] != 0:\n",
        "                    continue\n",
        "\n",
        "                # Create new node\n",
        "                new_node = Node(current_node, node_position)\n",
        "\n",
        "                # Append\n",
        "                children.append(new_node)\n",
        "\n",
        "            # Loop through children\n",
        "            for child in children:\n",
        "\n",
        "                # Child is on the closed list\n",
        "                for closed_child in closed_list:\n",
        "                    if child == closed_child:\n",
        "                        continue\n",
        "\n",
        "                # Create the f, g, and h values\n",
        "                child.g = current_node.g + np.linalg.norm(self.nodes[child.position[0]*self.N + child.position[1]] - self.nodes[end_node.position[0]*self.N + end_node.position[1]], ord=2)\n",
        "                child.h = ((child.position[0] - end_node.position[0]) ** 2) + ((child.position[1] - end_node.position[1]) ** 2)\n",
        "                child.f = child.g + child.h\n",
        "\n",
        "                # Child is already in the open list\n",
        "                for open_node in open_list:\n",
        "                    if child == open_node and child.g > open_node.g:\n",
        "                        continue\n",
        "\n",
        "                # Add the child to the open list\n",
        "                open_list.append(child)\n",
        "\n",
        "    def euclidian_distance_between_topographic_points(self, list_of_points):\n",
        "        counter = 0\n",
        "        first_point = list_of_points[0]\n",
        "        for point in list_of_points[1:]:\n",
        "          counter += np.linalg.norm(self.nodes[first_point[0]*self.N + first_point[1]] - self.nodes[point[0]*self.N + point[1]], ord=2)\n",
        "          first_point = point\n",
        "        return counter\n",
        "\n",
        "    def euclidian_comparison(self):\n",
        "        grid = [[0 for i in range(som.N)] for j in range(som.N)]\n",
        "        distance_between_data_points = [] # walking distance between two people\n",
        "        distance_from_data_point1_to_bmu = [] # walking distance to train station\n",
        "        distance_from_data_point2_to_bmu = [] # walking distance to train station\n",
        "        distance_between_bmus_diagonal = [] # drving distance between train stations\n",
        "        distance_between_bmus_edges = [] # railway distance between train stations\n",
        "        index_arr = np.random.randint(len(self.teachers),size=len(self.teachers)) #first num is # of data points, second num is # of iterations\n",
        "        bmu1 = self._best_matching_unit(self.teachers[index_arr[0]])\n",
        "        data_point1 = index_arr[0]\n",
        "        for data_point2 in index_arr[1:]:\n",
        "            bmu2 = self._best_matching_unit(self.teachers[data_point2])\n",
        "            path = som.astar(grid, (bmu1[0], bmu2[1]), (bmu2[0], bmu2[1]))\n",
        "            distance_between_data_points.append(np.linalg.norm(self.teachers[data_point1] - self.teachers[data_point2], ord=2))\n",
        "            distance_from_data_point1_to_bmu.append(np.linalg.norm(self.teachers[data_point1] - self.nodes[bmu1[0]*self.N + bmu1[1]], ord=2))\n",
        "            distance_from_data_point2_to_bmu.append(np.linalg.norm(self.teachers[data_point2] - self.nodes[bmu2[0]*self.N + bmu2[1]], ord=2))\n",
        "            distance_between_bmus_diagonal.append(np.linalg.norm(self.nodes[bmu1[0]*self.N + bmu1[1]] - self.nodes[bmu2[0]*self.N + bmu2[1]], ord=2))\n",
        "            distance_between_bmus_edges.append(som.euclidian_distance_between_topographic_points(path))\n",
        "            bmu1 = bmu2\n",
        "            data_point1 = data_point2\n",
        "        information = [[\"Distance between data points:\", (\"Mean\", statistics.mean(distance_between_data_points)), (\"Median\", statistics.median(distance_between_data_points)), (\"Stdev\", statistics.stdev(distance_between_data_points)), (\"Range\", max(distance_between_data_points) - min(distance_between_data_points))],\n",
        "                       [\"Distance between data point1 to bmu:\", (\"Mean\", statistics.mean(distance_from_data_point1_to_bmu)), (\"Median\", statistics.median(distance_from_data_point1_to_bmu)), (\"Stdev\", statistics.stdev(distance_from_data_point1_to_bmu)), (\"Range\", max(distance_from_data_point1_to_bmu) - min(distance_from_data_point1_to_bmu))],\n",
        "                       [\"Distance between data point2 to bmu:\", (\"Mean\", statistics.mean(distance_from_data_point2_to_bmu)), (\"Median\", statistics.median(distance_from_data_point2_to_bmu)), (\"Stdev\", statistics.stdev(distance_from_data_point2_to_bmu)), (\"Range\", max(distance_from_data_point2_to_bmu) - min(distance_from_data_point2_to_bmu))],\n",
        "                       [\"Distance between bmus diagonal:\", (\"Mean\", statistics.mean(distance_between_bmus_diagonal)), (\"Median\", statistics.median(distance_between_bmus_diagonal)), (\"Stdev\", statistics.stdev(distance_between_bmus_diagonal)), (\"Range\", max(distance_between_bmus_diagonal) - min(distance_between_bmus_diagonal))],\n",
        "                       [\"Distance between bmus along edges:\", (\"Mean\", statistics.mean(distance_between_bmus_edges)), (\"Median\", statistics.median(distance_between_bmus_edges)), (\"Stdev\", statistics.stdev(distance_between_bmus_edges)), (\"Range\", max(distance_between_bmus_edges) - min(distance_between_bmus_edges))]]\n",
        "        return information\n",
        "\n",
        "def heron(a, b, c):\n",
        "    s = 0.5 * (a + b + c)\n",
        "    area = math.sqrt(s * (s - a) * (s - b) * (s - c))\n",
        "    return area\n",
        "\n",
        "def distance(a, b):\n",
        "    sum = 0\n",
        "    for i in range(len(a)):\n",
        "        sum = sum + pow((a[i] - b[i]), 2)\n",
        "    return pow(sum, 0.5)\n",
        "\n",
        "def sklearn_iris():\n",
        "    # Load data\n",
        "    iris = load_iris(as_frame=True)\n",
        "    # Create a dataframe\n",
        "    df = iris['data'].join(iris['target'])\n",
        "\n",
        "    random_d = df.values.tolist()\n",
        "    for i in (random_d): #trying to delete any string in the dataset\n",
        "      for j in range(len(i)-1, -1, -1):\n",
        "        if type(i[j]) == str:\n",
        "          i.remove(i[j])\n",
        "\n",
        "    iris_som = SOM(dataset=df, initMethod=\"random\", N=20, size=10000, seed=None)\n",
        "\n",
        "\n",
        "# Initialize our SOM\n",
        "som = SOM(dataset=\"swiss_roll\", topoMap = \"square\", initMethod=\"random\", N=10, size=10000, seed=None)\n",
        "#som_to_compare = SOM(dataset=\"nocolor_point_cloud\", topoMap = \"square\", initMethod=\"random\", N=10, size=10000, seed=None) # 20x20 grid\n",
        "\n",
        "# Initial map\n",
        "som.plot_dataset()\n",
        "som.plot_nodes()\n",
        "plt.show()\n",
        "\n",
        "# Training\n",
        "#som.train()\n",
        "som.train_log()\n",
        "#indexList = [1,2,3,4,5,6,7,8,9,10]\n",
        "#som.train_list(indexList)\n",
        "\n",
        "# Final map\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = plt.axes(projection='3d')\n",
        "som.plot_dataset(fig, ax)\n",
        "som.plot_nodes(fig, ax)\n",
        "plt.show()\n",
        "\n",
        "# Visualization methods\n",
        "# som.edge_map()\n",
        "# som.u_matrix()\n",
        "som.button_plot()\n",
        "#information = som.euclidian_comparison()\n",
        "#for array in information:\n",
        "#  print(array)\n",
        "\n",
        "\n",
        "# Error calculations\n",
        "#color_list = som.grader(5)\n",
        "#nocolor_list = som_to_compare.grader(5)\n",
        "\n",
        "#print(\"\\nWith color init: \", color_list)\n",
        "#print(\"Without color init: \", nocolor_list)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}